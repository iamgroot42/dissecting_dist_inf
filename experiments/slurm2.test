#!/bin/bash
#SBATCH --job-name="CelebA training"
#SBATCH --output="rv%a.out"
#SBATCH --partition=gpu
#SBATCH --gres=gpu:4
#SBATCH --nodelist=adriatic01
#SBATCH --cpus-per-task=24
OFFSETS=(0 50 100 150 200 250 300 350 400 450)
source /etc/profile.d/modules.sh
./do_all.sh "0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0" victim ${OFFSETS[$SLURM_ARRAY_TASK_ID]}
#nohup python metrics.py --load_config race_metric.json --en race --ratios 0.0 0.1 0.2 0.3 0.4 0.6 0.7 0.8 0.9 1.0 2>&1 > m.out &
#nohup python comparison_load.py --load_config nc_comp.json --en sex_comp_50m --pred_name sex_comp &
wait
echo "finished"

